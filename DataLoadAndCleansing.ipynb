{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d0be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import nbimporter\n",
    "import Useful_Visualization_Functions\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "# from pyspark.sql.functions import col, explode, array, lit, lead, when, substring\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387b62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import Row\n",
    "# from pyspark.sql.functions import lit, col, column, expr, desc, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8da508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib\n",
    "# ! pip install seaborn\n",
    "# ! pip install ipynb\n",
    "# ! pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e5c799b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 111] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# build our own SparkSession\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m myspark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAWS-Spark\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.driver.memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m12g\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.shuffle.partitions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.repl.eagereval.enabled\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py:233\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     session \u001b[38;5;241m=\u001b[39m SparkSession(sc)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 233\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msessionState\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconf()\u001b[38;5;241m.\u001b[39msetConfString(key, value)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:281\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:288\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:402\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused"
     ]
    }
   ],
   "source": [
    "# build our own SparkSession\n",
    "myspark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AWS-Spark\")\\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d2d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.14.181.125:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AWS-Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f91ad3905b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e89599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25933550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! head noaa.csv\n",
    "# noaa_data.show(10)\n",
    "#noaa_data = myspark.read.load(\"noaa.csv\", format=\"csv\", sep=\",\", header=True, inferSchema=True)\n",
    "noaa_csv_pathname = \"noaa.csv\"\n",
    "\n",
    "noaa_data = myspark.read.load(noaa_csv_pathname, format=\"csv\", sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "noaa_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277aed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noaa_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82911c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_filt = (noaa_data.filter(noaa_data.ELEVATION <= 5))\n",
    "# temp_filt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43d04d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#latitude_order = noaa_data.orderBy(\"LATITUDE\", ascending=False)\n",
    "#latitude_order.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31b3512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noaa_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f9f9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+\n",
      "|TEMP|ELEVATION|VISIB|\n",
      "+----+---------+-----+\n",
      "|22.5|      9.0|  9.8|\n",
      "|21.0|      9.0| 14.0|\n",
      "|21.6|      9.0| 11.9|\n",
      "|19.5|      9.0|  7.3|\n",
      "|11.4|      9.0|  0.7|\n",
      "|12.8|      9.0|  4.8|\n",
      "|12.1|      9.0|  3.9|\n",
      "|25.8|      9.0|  6.2|\n",
      "|29.9|      9.0|  4.4|\n",
      "|35.8|      9.0|  5.4|\n",
      "+----+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noaa_data.select(\"TEMP\", \"ELEVATION\", \"VISIB\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69c93883-e0e9-45c1-9213-66e728fbc2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:================================================>        (38 + 7) / 45]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25933550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "noaa_data = noaa_data.withColumn(\"ItRained\", when((F.length(noaa_data[\"FRSHTT\"]) <= 4), lit(0)) \\\n",
    "                    .when(F.length(noaa_data[\"FRSHTT\"]) == 5, lit(1)) \\\n",
    "                    .otherwise(lit(substring('FRSHTT', 2, 1).cast(IntegerType()))) \\\n",
    ")\n",
    "\n",
    "#noaa_data.show(10)\n",
    "noaa_data = noaa_data.withColumn( \"NextDay\", lead(\"ItRained\", default=2).over(Window.orderBy(\"STATION\")).alias(\"Next\") )\n",
    "print(noaa_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54a464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor cl in columns:\\n    noaa_data.describe(cl).show()\\n\\nfor cl in columns:\\n    noaa_data.select(cl).distinct().show(10)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = noaa_data.columns\n",
    "\"\"\"\n",
    "for cl in columns:\n",
    "    noaa_data.describe(cl).show()\n",
    "\n",
    "for cl in columns:\n",
    "    noaa_data.select(cl).distinct().show(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52fe125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"NAME\", \"TEMP_ATTRIBUTES\", \"DEWP_ATTRIBUTES\",\n",
    "               \"SLP_ATTRIBUTES\", \"STP_ATTRIBUTES\", \"VISIB_ATTRIBUTES\", \"WDSP_ATTRIBUTES\", \"MAX_ATTRIBUTES\",\n",
    "               \"MIN_ATTRIBUTES\", \"PRCP_ATTRIBUTES\", \"GUST\", \"ItRained\"]\n",
    "\n",
    "cols_interest = [x for x in columns if x not in cols_to_drop]\n",
    "df_interest_cols = noaa_data.select(cols_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fa6f5",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9de037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      " |-- NextDay: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/24 11:00:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:00:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor cl in df_clean.columns: \\n    print(cl)\\n    df_clean.select(cl).summary().show()\\ndf_clean.select(\"ItRained\").summary().show()\\n\\nfor cl in columns:\\n    df_clean.describe(cl).show()\\n\\n\\nfor cl in columns:\\n    df_clean.select(cl).distinct().show(10)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interest_cols.printSchema()\n",
    "df_clean = df_interest_cols.dropna()\n",
    "[df_interest_cols.count(), df_clean.count()]\n",
    "\n",
    "columns = df_clean.columns\n",
    "\n",
    "\"\"\"\n",
    "for cl in df_clean.columns: \n",
    "    print(cl)\n",
    "    df_clean.select(cl).summary().show()\n",
    "df_clean.select(\"ItRained\").summary().show()\n",
    "\n",
    "for cl in columns:\n",
    "    df_clean.describe(cl).show()\n",
    "\n",
    "\n",
    "for cl in columns:\n",
    "    df_clean.select(cl).distinct().show(10)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9a4aa2c-d3ec-4e61-9ce9-4852cb5eb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/24 11:01:08 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:01:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25933550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntemp_median = df_clean_pd[\\'TEMP\\'].quantile(0.50)\\ndf_clean_pd[\\'TEMP\\'] = np.where(df_clean_pd[\\'TEMP\\'] < -10, temp_median, df_clean_pd[\\'TEMP\\'])\\nplt.boxplot(df_clean_pd[\"TEMP\"])\\nplt.show()\\n\\ndewp_median = df_clean_pd[\\'DEWP\\'].quantile(0.50)\\ndf_clean_pd[\\'DEWP\\'] = np.where(df_clean_pd[\\'DEWP\\'] > 100, dewp_median, df_clean_pd[\\'DEWP\\'])\\nplt.boxplot(df_clean_pd[\"DEWP\"])\\nplt.show()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_clean.count())\n",
    "\n",
    "df_clean = df_clean.filter(df_clean.TEMP > -10)\n",
    "df_clean = df_clean.filter(df_clean.DEWP < 100)\n",
    "df_clean = df_clean.filter(df_clean.SLP < 4000)\n",
    "df_clean = df_clean.filter(df_clean.STP < 100)\n",
    "df_clean = df_clean.filter(df_clean.VISIB < 100)\n",
    "df_clean = df_clean.filter(df_clean.WDSP < 100)\n",
    "df_clean = df_clean.filter(df_clean.MXSPD < 100)\n",
    "# df_clean = df_clean.filter(df_clean.GUST < 100)\n",
    "df_clean = df_clean.filter(df_clean.MAX < 100)\n",
    "df_clean = df_clean.filter(df_clean.MIN < 100)\n",
    "df_clean = df_clean.filter(df_clean.PRCP < 100)\n",
    "df_clean = df_clean.filter(df_clean.SNDP < 100)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "temp_median = df_clean_pd['TEMP'].quantile(0.50)\n",
    "df_clean_pd['TEMP'] = np.where(df_clean_pd['TEMP'] < -10, temp_median, df_clean_pd['TEMP'])\n",
    "plt.boxplot(df_clean_pd[\"TEMP\"])\n",
    "plt.show()\n",
    "\n",
    "dewp_median = df_clean_pd['DEWP'].quantile(0.50)\n",
    "df_clean_pd['DEWP'] = np.where(df_clean_pd['DEWP'] > 100, dewp_median, df_clean_pd['DEWP'])\n",
    "plt.boxplot(df_clean_pd[\"DEWP\"])\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb85ab95-726f-44bb-83f5-b03de4b673dc",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d25d075-c1e4-4514-9c8b-6097cdc0d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/24 11:01:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:01:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:02:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/24 11:02:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:02:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:02:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:03:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:03:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:03:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:04:01 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:04:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:04:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:04:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/24 11:04:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 35:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           NextDay|\n",
      "+-------+------------------+\n",
      "|  count|            115857|\n",
      "|   mean|0.5219278938691663|\n",
      "| stddev|0.4995210918182815|\n",
      "|    min|                 0|\n",
      "|    25%|                 0|\n",
      "|    50%|                 1|\n",
      "|    75%|                 1|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_clean.count())\n",
    "zero_df = df_clean.filter(col(\"NextDay\") == 0)\n",
    "one_df = df_clean.filter(col(\"NextDay\") == 1)\n",
    "\n",
    "# major_df, minor_df = zero_df, one_df if zero_df.count() > one_df.count() else one_df, zero_df\n",
    "\n",
    "if zero_df.count() > one_df.count():\n",
    "    major_df = zero_df\n",
    "    minor_df = one_df\n",
    "else:\n",
    "    major_df = one_df\n",
    "    minor_df = zero_df\n",
    "    \n",
    "ratio = major_df.count()/minor_df.count()\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "df_clean = sampled_majority_df.unionAll(minor_df)\n",
    "df_clean.select(\"NextDay\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "989231f0-c7f5-44bd-a9e8-d6899af869e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuno/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuno/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/nuno/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuno/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 480, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nuno/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/nuno/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o161.write",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m cleanfilename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean-noaa\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf_clean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241m.\u001b[39mmode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mparquet(cleanfilename)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:246\u001b[0m, in \u001b[0;36mDataFrame.write\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    Interface for saving the content of the non-streaming :class:`DataFrame` out into external\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    storage.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    :class:`DataFrameWriter`\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/readwriter.py:543\u001b[0m, in \u001b[0;36mDataFrameWriter.__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msql_ctx\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o161.write"
     ]
    }
   ],
   "source": [
    "cleanfilename = \"clean-noaa\"\n",
    "df_clean.write.mode(\"overwrite\").parquet(cleanfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5cef332-5849-4d80-ba33-c4edaa8aa1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:29:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:29:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:29:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 348:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60783 rows in the training set and 15055 in the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df_clean = myspark.createDataFrame(df_clean_pd)\n",
    "#df_train, df_test = df_clean.randomSplit([0.8,0.2], seed = 42)\n",
    "#df_train.cache()\n",
    "#print(f\"There are {df_train.count()} rows in the training set and {df_test.count()} in the test set\")\n",
    "\n",
    "df_train_n, df_test_n = df_clean_n.randomSplit([0.8,0.2], seed = 42)\n",
    "df_train_n.cache()\n",
    "print(f\"There are {df_train_n.count()} rows in the training set and {df_test_n.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6883501f-c09a-4204-822f-ade89542085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:30:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 420:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  41.806708734639656 2 % \n",
      "True Negative:  31.8365991364995 % \n",
      "False Positive:  18.432414480239125 % \n",
      "False Negative:  7.924277648621721 % \n",
      "Prediction count: 15055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprediction_label = df_prediction.select(\"prediction\", \"ItRained\")\\n\\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\\'prediction\\')\\n\\nprint(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\\n\\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"ItRained\")\\nlr_model = lr.fit(vec_df_train)\\navg_ItRained = float(df_train.select(avg(\"ItRained\")).first()[0])\\ndf_pred = df_train.withColumn(\"avg_ItRained_prediction\", lit(avg_ItRained))\\navg_ItRained\\nevaluator = RegressionEvaluator(predictionCol=\"avg_ItRained_prediction\", labelCol=\"ItRained\", metricName=\"rmse\")\\nprint(f\"The RMSE for predicting the average frshtt is: {evaluator.evaluate(df_pred):.2f}\")\\npipeline = Pipeline(stages=[vec_assembler, lr_model])\\n\\n# get the model (as transformer)\\npipeline_model = pipeline.fit(df_train)\\ndf_prediction = pipeline_model.transform(df_test)\\n\\n# show the columns worth to be looked at\\ndf_prediction.select(\"features\",\"ItRained\",\"prediction\").sample(False, 0.1).sort(\"ItRained\", ascending=False).show(200)\\n\\ndf_prediction.columns\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vec_assembler = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "#vec_df_train = vec_assembler.transform(df_train)\n",
    "#\n",
    "## show the content of the columns bedrooms, features and price\n",
    "## vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "#\n",
    "#lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"ItRained\")\n",
    "#pipeline = Pipeline(stages=[vec_assembler, lsvc])\n",
    "#pipeline_model = pipeline.fit(df_train)\n",
    "#df_prediction = pipeline_model.transform(df_test)\n",
    "## df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "#\n",
    "#prediction_label = df_prediction.select(\"prediction\", \"ItRained\")  \n",
    "#\n",
    "## supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "## it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "#\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='ItRained', )\n",
    "#\n",
    "## print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "#\n",
    "#n = df_prediction.count()\n",
    "#tp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"ItRained == prediction\")).count()\n",
    "#tn = df_prediction.filter(expr(\"prediction <= 0\") & expr(\"ItRained == prediction\")).count()\n",
    "#fp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"ItRained != prediction\")).count()\n",
    "#fn = n - tp - tn - fp\n",
    "#print(\"True Positive: \",tp/n * 100, 2,\"%\", \"\\nTrue Negative: \", tn/n * 100,\"%\",\n",
    "#      \"\\nFalse Positive: \", fp/n * 100 ,\"%\", \"\\nFalse Negative: \", fn/n * 100,\"%\", \n",
    "#      \"\\nPrediction count:\", n)\n",
    "\n",
    "\n",
    "#====================================================================================================================================================\n",
    "\n",
    "vec_assembler_n = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "vec_df_train_n = vec_assembler_n.transform(df_train_n)\n",
    "\n",
    "# show the content of the columns bedrooms, features and price\n",
    "# vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "\n",
    "lsvc_n = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"NextDay\")\n",
    "pipeline_n = Pipeline(stages=[vec_assembler_n, lsvc_n])\n",
    "pipeline_model_n = pipeline_n.fit(df_train_n)\n",
    "df_prediction_n = pipeline_model_n.transform(df_test_n)\n",
    "# df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "\n",
    "prediction_label_n = df_prediction_n.select(\"prediction\", \"NextDay\")  \n",
    "\n",
    "# supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "# it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "evaluator_n = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='NextDay', )\n",
    "\n",
    "# print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "n_n = df_prediction_n.count()\n",
    "tp_n = df_prediction_n.filter(expr(\"prediction > 0\") & expr(\"NextDay == prediction\")).count()\n",
    "tn_n = df_prediction_n.filter(expr(\"prediction <= 0\") & expr(\"NextDay == prediction\")).count()\n",
    "fp_n = df_prediction_n.filter(expr(\"prediction > 0\") & expr(\"NextDay != prediction\")).count()\n",
    "fn_n = n_n - tp_n - tn_n - fp_n\n",
    "print(\"True Positive: \",tp_n/n_n * 100, 2,\"%\", \"\\nTrue Negative: \", tn_n/n_n * 100,\"%\",\n",
    "      \"\\nFalse Positive: \", fp_n/n_n * 100 ,\"%\", \"\\nFalse Negative: \", fn_n/n_n * 100,\"%\", \n",
    "      \"\\nPrediction count:\", n_n)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "prediction_label = df_prediction.select(\"prediction\", \"ItRained\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "\n",
    "print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"ItRained\")\n",
    "lr_model = lr.fit(vec_df_train)\n",
    "avg_ItRained = float(df_train.select(avg(\"ItRained\")).first()[0])\n",
    "df_pred = df_train.withColumn(\"avg_ItRained_prediction\", lit(avg_ItRained))\n",
    "avg_ItRained\n",
    "evaluator = RegressionEvaluator(predictionCol=\"avg_ItRained_prediction\", labelCol=\"ItRained\", metricName=\"rmse\")\n",
    "print(f\"The RMSE for predicting the average frshtt is: {evaluator.evaluate(df_pred):.2f}\")\n",
    "pipeline = Pipeline(stages=[vec_assembler, lr_model])\n",
    "\n",
    "# get the model (as transformer)\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "df_prediction = pipeline_model.transform(df_test)\n",
    "\n",
    "# show the columns worth to be looked at\n",
    "df_prediction.select(\"features\",\"ItRained\",\"prediction\").sample(False, 0.1).sort(\"ItRained\", ascending=False).show(200)\n",
    "\n",
    "df_prediction.columns\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
