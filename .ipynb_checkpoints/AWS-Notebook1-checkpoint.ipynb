{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d0be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import nbimporter\n",
    "import Useful_Visualization_Functions\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387b62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import Row\n",
    "# from pyspark.sql.functions import lit, col, column, expr, desc, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8da508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib\n",
    "# ! pip install seaborn\n",
    "# ! pip install ipynb\n",
    "# ! pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5c799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/18 12:01:33 WARN Utils: Your hostname, nuno-g14 resolves to a loopback address: 127.0.1.1; using 192.168.1.225 instead (on interface wlp2s0)\n",
      "22/05/18 12:01:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/nuno/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/18 12:01:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# build our own SparkSession\n",
    "myspark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AWS-Spark\")\\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d2d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://nuno-g14.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AWS-Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2722b9fe80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e89599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25933550"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! head noaa.csv\n",
    "# noaa_data.show(10)\n",
    "noaa_data = myspark.read.load(\"noaa.csv\", format=\"csv\", sep=\",\", header=True, inferSchema=True)\n",
    "noaa_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277aed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noaa_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82911c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_filt = (noaa_data.filter(noaa_data.ELEVATION <= 5))\n",
    "# temp_filt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43d04d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#latitude_order = noaa_data.orderBy(\"LATITUDE\", ascending=False)\n",
    "#latitude_order.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31b3512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noaa_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f9f9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+\n",
      "|TEMP|ELEVATION|VISIB|\n",
      "+----+---------+-----+\n",
      "|22.5|      9.0|  9.8|\n",
      "|21.0|      9.0| 14.0|\n",
      "|21.6|      9.0| 11.9|\n",
      "|19.5|      9.0|  7.3|\n",
      "|11.4|      9.0|  0.7|\n",
      "|12.8|      9.0|  4.8|\n",
      "|12.1|      9.0|  3.9|\n",
      "|25.8|      9.0|  6.2|\n",
      "|29.9|      9.0|  4.4|\n",
      "|35.8|      9.0|  5.4|\n",
      "+----+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noaa_data.select(\"TEMP\", \"ELEVATION\", \"VISIB\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69c93883-e0e9-45c1-9213-66e728fbc2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+----------+---------+--------------------+----+---------------+----+---------------+------+--------------+----+--------------+-----+----------------+----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+--------+\n",
      "|    STATION|      DATE|  LATITUDE| LONGITUDE|ELEVATION|                NAME|TEMP|TEMP_ATTRIBUTES|DEWP|DEWP_ATTRIBUTES|   SLP|SLP_ATTRIBUTES| STP|STP_ATTRIBUTES|VISIB|VISIB_ATTRIBUTES|WDSP|WDSP_ATTRIBUTES|MXSPD| GUST| MAX|MAX_ATTRIBUTES| MIN|MIN_ATTRIBUTES|PRCP|PRCP_ATTRIBUTES| SNDP|FRSHTT|ItRained|\n",
      "+-----------+----------+----------+----------+---------+--------------------+----+---------------+----+---------------+------+--------------+----+--------------+-----+----------------+----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+--------+\n",
      "|01001099999|2018-01-01|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|22.5|           24.0|15.5|           24.0|1006.2|          24.0| 5.0|          24.0|  9.8|             6.0|24.0|           24.0| 36.9|999.9|29.1|             *|18.9|             *|0.01|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-02|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|21.0|           24.0|13.3|           24.0|1009.3|          24.0| 8.1|          24.0| 14.0|             6.0|13.3|           24.0| 19.4|999.9|22.8|              |18.7|              | 0.0|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-03|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|21.6|           24.0|15.1|           24.0|1011.8|          24.0|10.6|          24.0| 11.9|             6.0| 7.3|           24.0| 15.7| 21.6|23.0|             *|17.8|             *| 0.0|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-04|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|19.5|           24.0|13.9|           24.0|1017.1|          24.0|15.9|          24.0|  7.3|             6.0|13.2|           24.0| 21.4| 25.4|24.4|             *|14.0|             *|0.02|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-05|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|11.4|           24.0| 4.1|           24.0|1021.8|          24.0|20.6|          24.0|  0.7|             6.0|19.8|           24.0| 23.3| 35.5|14.7|             *| 8.2|             *| 0.0|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-06|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|12.8|           24.0| 4.4|           24.0|1018.7|          24.0|17.5|          24.0|  4.8|             6.0|14.9|           24.0| 18.8| 29.3|15.4|             *| 9.5|             *|0.04|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-07|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|12.1|           24.0| 4.4|           24.0|1015.1|          24.0|13.9|          24.0|  3.9|             6.0|18.4|           24.0| 27.2| 40.6|13.1|             *| 9.0|              |0.01|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-08|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|25.8|           24.0|22.1|           24.0|1001.7|          24.0| 0.5|          24.0|  6.2|             6.0|18.9|           24.0| 33.0| 41.6|34.5|              |11.8|              | 0.0|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-09|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|29.9|           24.0|26.6|           24.0|1007.2|          24.0| 6.0|          24.0|  4.4|             6.0|15.0|           23.0| 36.9|999.9|35.2|             *|25.2|             *|0.26|              G|999.9|  1000|       0|\n",
      "|01001099999|2018-01-10|70.9333333|-8.6666667|      9.0|JAN MAYEN NOR NAV...|35.8|           24.0|34.2|           24.0|1010.9|          24.0| 9.7|          24.0|  5.4|             6.0|11.4|           24.0| 17.5|999.9|37.4|             *|31.6|              |0.04|              G|999.9|110000|       1|\n",
      "+-----------+----------+----------+----------+---------+--------------------+----+---------------+----+---------------+------+--------------+----+--------------+-----+----------------+----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/18 12:02:48 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "noaa_data = noaa_data.withColumn(\"ItRained\", when((F.length(noaa_data[\"FRSHTT\"]) <= 4), lit(0)) \\\n",
    "                    .when(F.length(noaa_data[\"FRSHTT\"]) == 5, lit(1)) \\\n",
    "                    .otherwise(lit(substring('FRSHTT', 2, 1).cast(IntegerType()))) \\\n",
    ")\n",
    "\n",
    "noaa_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d54a464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor cl in columns:\\n    noaa_data.describe(cl).show()\\n\\nfor cl in columns:\\n    noaa_data.select(cl).distinct().show(10)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "columns = noaa_data.columns\n",
    "\"\"\"\n",
    "for cl in columns:\n",
    "    noaa_data.describe(cl).show()\n",
    "\n",
    "for cl in columns:\n",
    "    noaa_data.select(cl).distinct().show(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a52fe125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"NAME\", \"TEMP_ATTRIBUTES\", \"DEWP_ATTRIBUTES\",\n",
    "               \"SLP_ATTRIBUTES\", \"STP_ATTRIBUTES\", \"VISIB_ATTRIBUTES\", \"WDSP_ATTRIBUTES\", \"MAX_ATTRIBUTES\",\n",
    "               \"MIN_ATTRIBUTES\", \"PRCP_ATTRIBUTES\", \"GUST\"]\n",
    "\n",
    "cols_interest = [x for x in columns if x not in cols_to_drop]\n",
    "df_interest_cols = noaa_data.select(cols_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fa6f5",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9de037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      " |-- ItRained: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=======================================>               (32 + 13) / 45]\r"
     ]
    }
   ],
   "source": [
    "df_interest_cols.printSchema()\n",
    "df_clean = df_interest_cols.dropna()\n",
    "[df_interest_cols.count(), df_clean.count()]\n",
    "\n",
    "columns = df_clean.columns\n",
    "\n",
    "df_clean.select(\"GUST\").summary().show()\n",
    "\n",
    "\"\"\"\n",
    "for cl in df_clean.columns: \n",
    "    print(cl)\n",
    "    df_clean.select(cl).summary().show()\n",
    "df_clean.select(\"ItRained\").summary().show()\n",
    "\"\"\"  \n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "for cl in columns:\n",
    "    df_clean.describe(cl).show()\n",
    "\n",
    "\n",
    "for cl in columns:\n",
    "    df_clean.select(cl).distinct().show(10)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25d075-c1e4-4514-9c8b-6097cdc0d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.createDataFrame([['a',1],['b',1],['c',1],['d',1], ['e',1], ['f',1], ['x', 0], ['y', 0]], ['feature', 'label'])\n",
    "# df.show()\n",
    "major_df = df_clean.filter(col(\"ItRained\") == 0)\n",
    "minor_df = df_clean.filter(col(\"ItRained\") == 1)\n",
    "ratio = major_df.count()/minor_df.count()\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "df_clean = sampled_majority_df.unionAll(minor_df)\n",
    "df_clean.select(\"ItRained\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a4aa2c-d3ec-4e61-9ce9-4852cb5eb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.filter(df_clean.TEMP > -10)\n",
    "df_clean = df_clean.filter(df_clean.DEWP < 100)\n",
    "df_clean = df_clean.filter(df_clean.SLP < 4000)\n",
    "df_clean = df_clean.filter(df_clean.STP < 100)\n",
    "df_clean = df_clean.filter(df_clean.VISIB < 100)\n",
    "df_clean = df_clean.filter(df_clean.WDSP < 100)\n",
    "df_clean = df_clean.filter(df_clean.MXSPD < 100)\n",
    "# df_clean = df_clean.filter(df_clean.GUST < 100)\n",
    "df_clean = df_clean.filter(df_clean.MAX < 100)\n",
    "df_clean = df_clean.filter(df_clean.MIN < 100)\n",
    "df_clean = df_clean.filter(df_clean.PRCP < 100)\n",
    "df_clean = df_clean.filter(df_clean.SNDP < 100)\n",
    "\n",
    "\"\"\"\n",
    "temp_median = df_clean_pd['TEMP'].quantile(0.50)\n",
    "df_clean_pd['TEMP'] = np.where(df_clean_pd['TEMP'] < -10, temp_median, df_clean_pd['TEMP'])\n",
    "plt.boxplot(df_clean_pd[\"TEMP\"])\n",
    "plt.show()\n",
    "\n",
    "dewp_median = df_clean_pd['DEWP'].quantile(0.50)\n",
    "df_clean_pd['DEWP'] = np.where(df_clean_pd['DEWP'] > 100, dewp_median, df_clean_pd['DEWP'])\n",
    "plt.boxplot(df_clean_pd[\"DEWP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_slp_filter = df_clean.filter(df_clean.SLP < 4000).toPandas()\n",
    "slp_median = df_clean_slp_filter['SLP'].quantile(0.50)\n",
    "df_clean_pd['SLP'] = np.where(df_clean_pd['SLP'] > 4000, slp_median, df_clean_pd['SLP'])\n",
    "plt.boxplot(df_clean_pd[\"SLP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_stp_filter = df_clean.filter(df_clean.STP < 100).toPandas()\n",
    "stp_median = df_clean_stp_filter['STP'].quantile(0.50)\n",
    "df_clean_pd['STP'] = np.where(df_clean_pd['STP'] > 100, stp_median, df_clean_pd['STP'])\n",
    "plt.boxplot(df_clean_pd[\"STP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_visib_filter = df_clean.filter(df_clean.VISIB < 100).toPandas()\n",
    "visib_median = df_clean_visib_filter['VISIB'].quantile(0.50)\n",
    "df_clean_pd['VISIB'] = np.where(df_clean_pd['VISIB'] > 100, visib_median, df_clean_pd['VISIB'])\n",
    "plt.boxplot(df_clean_pd[\"VISIB\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_wdsp_filter = df_clean.filter(df_clean.WDSP < 100).toPandas()\n",
    "wdsp_median = df_clean_wdsp_filter['WDSP'].quantile(0.50)\n",
    "df_clean_pd['WDSP'] = np.where(df_clean_pd['WDSP'] > 100, wdsp_median, df_clean_pd['WDSP'])\n",
    "plt.boxplot(df_clean_pd[\"WDSP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_mxspd_filter = df_clean.filter(df_clean.MXSPD < 100).toPandas()\n",
    "mxspd_median = df_clean_mxspd_filter['MXSPD'].quantile(0.50)\n",
    "df_clean_pd['MXSPD'] = np.where(df_clean_pd['MXSPD'] > 100, mxspd_median, df_clean_pd['MXSPD'])\n",
    "plt.boxplot(df_clean_pd[\"MXSPD\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_gust_filter = df_clean.filter(df_clean.GUST < 100).toPandas()\n",
    "gust_median = df_clean_gust_filter['GUST'].quantile(0.50)\n",
    "df_clean_pd['GUST'] = np.where(df_clean_pd['GUST'] > 100, gust_median, df_clean_pd['GUST'])\n",
    "plt.boxplot(df_clean_pd[\"GUST\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_max_filter = df_clean.filter(df_clean.MAX < 100).toPandas()\n",
    "max_median = df_clean_max_filter['MAX'].quantile(0.50)\n",
    "df_clean_pd['MAX'] = np.where((df_clean_pd['MAX'] < 100) & (df_clean_pd['MAX'] > -10), df_clean_pd['MAX'], max_median)\n",
    "plt.boxplot(df_clean_pd[\"MAX\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_min_filter = df_clean.filter(df_clean.MIN < 100).toPandas()\n",
    "min_median = df_clean_max_filter['MIN'].quantile(0.50)\n",
    "df_clean_pd['MIN'] = np.where((df_clean_pd['MIN'] < 100) & (df_clean_pd['MIN'] > -10), df_clean_pd['MIN'], min_median)\n",
    "plt.boxplot(df_clean_pd[\"MIN\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_prcp_filter = df_clean.filter(df_clean.PRCP < 100).toPandas()\n",
    "prcp_median = df_clean_prcp_filter['PRCP'].quantile(0.50)\n",
    "df_clean_pd['PRCP'] = np.where(df_clean_pd['PRCP'] > 50, prcp_median, df_clean_pd['PRCP'])\n",
    "plt.boxplot(df_clean_pd[\"PRCP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_sndp_filter = df_clean.filter(df_clean.SNDP < 100).toPandas()\n",
    "sndp_median = df_clean_sndp_filter['SNDP'].quantile(0.50)\n",
    "df_clean_pd['SNDP'] = np.where(df_clean_pd['SNDP'] > 200, sndp_median, df_clean_pd['SNDP'])\n",
    "plt.boxplot(df_clean_pd[\"SNDP\"])\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cef332-5849-4d80-ba33-c4edaa8aa1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean = myspark.createDataFrame(df_clean_pd)\n",
    "df_train, df_test = df_clean.randomSplit([0.8,0.2], seed = 42)\n",
    "df_train.cache()\n",
    "print(f\"There are {df_train.count()} rows in the training set and {df_test.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6883501f-c09a-4204-822f-ade89542085f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'GUST', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "vec_df_train = vec_assembler.transform(df_train)\n",
    "\n",
    "# show the content of the columns bedrooms, features and price\n",
    "# vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"ItRained\")\n",
    "pipeline = Pipeline(stages=[vec_assembler, lsvc])\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "df_prediction = pipeline_model.transform(df_test)\n",
    "df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "\n",
    "prediction_label = df_prediction.select(\"prediction\", \"ItRained\")  \n",
    "\n",
    "# supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "# it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='ItRained', )\n",
    "\n",
    "# print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "n = df_prediction.count()\n",
    "tp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"ItRained == prediction\")).count()\n",
    "tn = df_prediction.filter(expr(\"prediction <= 0\") & expr(\"ItRained == prediction\")).count()\n",
    "fp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"ItRained != prediction\")).count()\n",
    "fn = n - tp - tn - fp\n",
    "print(\"True Positive: \",tp/n * 100, 2,\"%\", \"\\nTrue Negative: \", tn/n * 100,\"%\",\n",
    "      \"\\nFalse Positive: \", fp/n * 100 ,\"%\", \"\\nFalse Negative: \", fn/n * 100,\"%\", \n",
    "      \"\\nPrediction count:\", n)\n",
    "\n",
    "\"\"\"\n",
    "prediction_label = df_prediction.select(\"prediction\", \"ItRained\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "\n",
    "print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"ItRained\")\n",
    "lr_model = lr.fit(vec_df_train)\n",
    "avg_ItRained = float(df_train.select(avg(\"ItRained\")).first()[0])\n",
    "df_pred = df_train.withColumn(\"avg_ItRained_prediction\", lit(avg_ItRained))\n",
    "avg_ItRained\n",
    "evaluator = RegressionEvaluator(predictionCol=\"avg_ItRained_prediction\", labelCol=\"ItRained\", metricName=\"rmse\")\n",
    "print(f\"The RMSE for predicting the average frshtt is: {evaluator.evaluate(df_pred):.2f}\")\n",
    "pipeline = Pipeline(stages=[vec_assembler, lr_model])\n",
    "\n",
    "# get the model (as transformer)\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "df_prediction = pipeline_model.transform(df_test)\n",
    "\n",
    "# show the columns worth to be looked at\n",
    "df_prediction.select(\"features\",\"ItRained\",\"prediction\").sample(False, 0.1).sort(\"ItRained\", ascending=False).show(200)\n",
    "\n",
    "df_prediction.columns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc457c-ab8e-4baf-bef9-034d17d1777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "# Compute raw scores on the test set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = lsvc\n",
    "\n",
    "predictionAndLabels = df_test.rdd.map(lambda lp: (float(model.predict(lp.features)), lp.label))\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "# Overall statistics\n",
    "precision = metrics.precision()\n",
    "recall = metrics.recall()\n",
    "f1Score = metrics.fMeasure()\n",
    "print(\"Summary Stats\")\n",
    "print(\"Precision = %s\" % precision)\n",
    "print(\"Recall = %s\" % recall)\n",
    "print(\"F1 Score = %s\" % f1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293991a-0014-42c0-9690-35d27269022a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572c282-22c9-4f2f-ad86-a0f8b97518d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99a62b-efc2-45c3-abe2-d7ae472e39f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf43eb5-fb88-4729-82c3-171965a25d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb1cff-8efc-4eda-8987-bb3d51d0488a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
