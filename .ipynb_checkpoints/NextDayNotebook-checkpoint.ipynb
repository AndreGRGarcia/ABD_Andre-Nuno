{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9d0be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import nbimporter\n",
    "import Useful_Visualization_Functions\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "#from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, explode, array, lit, lead\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387b62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import Row\n",
    "# from pyspark.sql.functions import lit, col, column, expr, desc, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8da508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install matplotlib\n",
    "# ! pip install seaborn\n",
    "# ! pip install ipynb\n",
    "# ! pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5c799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 14:33:35 WARN Utils: Your hostname, saltedcookie-PC resolves to a loopback address: 127.0.1.1; using 192.168.1.199 instead (on interface enp42s0)\n",
      "22/05/23 14:33:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/23 14:33:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# build our own SparkSession\n",
    "myspark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AWS-Spark\")\\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d2d3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-TL80VNL.Home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AWS-Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe14435b160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12e89599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17840652"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! head noaa.csv\n",
    "# noaa_data.show(10)\n",
    "#noaa_data = myspark.read.load(\"noaa.csv\", format=\"csv\", sep=\",\", header=True, inferSchema=True)\n",
    "noaa_data = myspark.read.load(\"/home/saltedcookie/Desktop/projetoABD/combined.csv\", format=\"csv\", sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "noaa_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277aed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noaa_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82911c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_filt = (noaa_data.filter(noaa_data.ELEVATION <= 5))\n",
    "# temp_filt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43d04d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#latitude_order = noaa_data.orderBy(\"LATITUDE\", ascending=False)\n",
    "#latitude_order.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d31b3512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: integer (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- ELEVATION: double (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- STP_ATTRIBUTES: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- GUST: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noaa_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f9f9a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+\n",
      "|TEMP|ELEVATION|VISIB|\n",
      "+----+---------+-----+\n",
      "|23.4|      9.0| 28.0|\n",
      "|31.5|      9.0|  4.9|\n",
      "|35.0|      9.0|  3.1|\n",
      "|35.4|      9.0|  6.1|\n",
      "|27.5|      9.0| 13.5|\n",
      "|23.6|      9.0|  8.6|\n",
      "|18.7|      9.0|  4.1|\n",
      "|26.9|      9.0|999.9|\n",
      "|31.7|      9.0|  5.9|\n",
      "|32.1|      9.0|  5.4|\n",
      "+----+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noaa_data.select(\"TEMP\", \"ELEVATION\", \"VISIB\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69c93883-e0e9-45c1-9213-66e728fbc2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 302:==========================================>            (24 + 7) / 31]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17840652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "noaa_data = noaa_data.withColumn(\"ItRained\", when((F.length(noaa_data[\"FRSHTT\"]) <= 4), lit(0)) \\\n",
    "                    .when(F.length(noaa_data[\"FRSHTT\"]) == 5, lit(1)) \\\n",
    "                    .otherwise(lit(substring('FRSHTT', 2, 1).cast(IntegerType()))) \\\n",
    ")\n",
    "\n",
    "#noaa_data.show(10)\n",
    "\n",
    "#cols = df.columns\n",
    "#df = df.withColumn(\"id\", f.monotonically_increasing_id())\n",
    "#df.select(\n",
    "#    \"*\", \n",
    "#    *([f.lag(f.col(c),default=0).over(Window.orderBy(\"id\")).alias(\"prev_\"+c) for c in cols] + \n",
    "#      [f.lead(f.col(c),default=0).over(Window.orderBy(\"id\")).alias(\"next_\"+c) for c in cols])\n",
    "#).drop(\"id\").show()\n",
    "\n",
    "noaa_data_n = noaa_data.withColumn( \"NextDay\", lead(\"ItRained\", default=2).over(Window.orderBy(\"STATION\")).alias(\"Next\") )\n",
    "print(noaa_data_n.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d54a464c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor cl in columns:\\n    noaa_data.describe(cl).show()\\n\\nfor cl in columns:\\n    noaa_data.select(cl).distinct().show(10)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#columns = noaa_data.columns\n",
    "\n",
    "columns_n = noaa_data_n.columns\n",
    "\"\"\"\n",
    "for cl in columns:\n",
    "    noaa_data.describe(cl).show()\n",
    "\n",
    "for cl in columns:\n",
    "    noaa_data.select(cl).distinct().show(10)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a52fe125",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"NAME\", \"TEMP_ATTRIBUTES\", \"DEWP_ATTRIBUTES\",\n",
    "               \"SLP_ATTRIBUTES\", \"STP_ATTRIBUTES\", \"VISIB_ATTRIBUTES\", \"WDSP_ATTRIBUTES\", \"MAX_ATTRIBUTES\",\n",
    "               \"MIN_ATTRIBUTES\", \"PRCP_ATTRIBUTES\", \"GUST\"]\n",
    "\n",
    "#cols_interest = [x for x in columns if x not in cols_to_drop]\n",
    "#df_interest_cols = noaa_data.select(cols_interest)\n",
    "\n",
    "cols_interest_n = [x for x in columns_n if x not in cols_to_drop]\n",
    "df_interest_cols_n = noaa_data_n.select(cols_interest_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845fa6f5",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a9de037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TEMP: double (nullable = true)\n",
      " |-- DEWP: double (nullable = true)\n",
      " |-- SLP: double (nullable = true)\n",
      " |-- STP: double (nullable = true)\n",
      " |-- VISIB: double (nullable = true)\n",
      " |-- WDSP: double (nullable = true)\n",
      " |-- MXSPD: double (nullable = true)\n",
      " |-- MAX: double (nullable = true)\n",
      " |-- MIN: double (nullable = true)\n",
      " |-- PRCP: double (nullable = true)\n",
      " |-- SNDP: double (nullable = true)\n",
      " |-- FRSHTT: integer (nullable = true)\n",
      " |-- ItRained: integer (nullable = true)\n",
      " |-- NextDay: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:27:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:27:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor cl in columns:\\n    df_clean.describe(cl).show()\\n\\n\\nfor cl in columns:\\n    df_clean.select(cl).distinct().show(10)\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_interest_cols.printSchema()\n",
    "#df_clean = df_interest_cols.dropna()\n",
    "#[df_interest_cols.count(), df_clean.count()]\n",
    "#\n",
    "#columns = df_clean.columns\n",
    "\n",
    "# df_clean.select(\"GUST\").summary().show()\n",
    "\n",
    "df_interest_cols_n.printSchema()\n",
    "df_clean_n = df_interest_cols_n.dropna()\n",
    "[df_interest_cols_n.count(), df_clean_n.count()]\n",
    "\n",
    "columns_n = df_clean_n.columns\n",
    "\n",
    "\"\"\"\n",
    "for cl in df_clean.columns: \n",
    "    print(cl)\n",
    "    df_clean.select(cl).summary().show()\n",
    "df_clean.select(\"ItRained\").summary().show()\n",
    "\"\"\"  \n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "for cl in columns:\n",
    "    df_clean.describe(cl).show()\n",
    "\n",
    "\n",
    "for cl in columns:\n",
    "    df_clean.select(cl).distinct().show(10)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9a4aa2c-d3ec-4e61-9ce9-4852cb5eb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:27:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:27:58 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 313:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17779327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntemp_median = df_clean_pd[\\'TEMP\\'].quantile(0.50)\\ndf_clean_pd[\\'TEMP\\'] = np.where(df_clean_pd[\\'TEMP\\'] < -10, temp_median, df_clean_pd[\\'TEMP\\'])\\nplt.boxplot(df_clean_pd[\"TEMP\"])\\nplt.show()\\n\\ndewp_median = df_clean_pd[\\'DEWP\\'].quantile(0.50)\\ndf_clean_pd[\\'DEWP\\'] = np.where(df_clean_pd[\\'DEWP\\'] > 100, dewp_median, df_clean_pd[\\'DEWP\\'])\\nplt.boxplot(df_clean_pd[\"DEWP\"])\\nplt.show()\\n\\ndf_clean_slp_filter = df_clean.filter(df_clean.SLP < 4000).toPandas()\\nslp_median = df_clean_slp_filter[\\'SLP\\'].quantile(0.50)\\ndf_clean_pd[\\'SLP\\'] = np.where(df_clean_pd[\\'SLP\\'] > 4000, slp_median, df_clean_pd[\\'SLP\\'])\\nplt.boxplot(df_clean_pd[\"SLP\"])\\nplt.show()\\n\\ndf_clean_stp_filter = df_clean.filter(df_clean.STP < 100).toPandas()\\nstp_median = df_clean_stp_filter[\\'STP\\'].quantile(0.50)\\ndf_clean_pd[\\'STP\\'] = np.where(df_clean_pd[\\'STP\\'] > 100, stp_median, df_clean_pd[\\'STP\\'])\\nplt.boxplot(df_clean_pd[\"STP\"])\\nplt.show()\\n\\ndf_clean_visib_filter = df_clean.filter(df_clean.VISIB < 100).toPandas()\\nvisib_median = df_clean_visib_filter[\\'VISIB\\'].quantile(0.50)\\ndf_clean_pd[\\'VISIB\\'] = np.where(df_clean_pd[\\'VISIB\\'] > 100, visib_median, df_clean_pd[\\'VISIB\\'])\\nplt.boxplot(df_clean_pd[\"VISIB\"])\\nplt.show()\\n\\ndf_clean_wdsp_filter = df_clean.filter(df_clean.WDSP < 100).toPandas()\\nwdsp_median = df_clean_wdsp_filter[\\'WDSP\\'].quantile(0.50)\\ndf_clean_pd[\\'WDSP\\'] = np.where(df_clean_pd[\\'WDSP\\'] > 100, wdsp_median, df_clean_pd[\\'WDSP\\'])\\nplt.boxplot(df_clean_pd[\"WDSP\"])\\nplt.show()\\n\\ndf_clean_mxspd_filter = df_clean.filter(df_clean.MXSPD < 100).toPandas()\\nmxspd_median = df_clean_mxspd_filter[\\'MXSPD\\'].quantile(0.50)\\ndf_clean_pd[\\'MXSPD\\'] = np.where(df_clean_pd[\\'MXSPD\\'] > 100, mxspd_median, df_clean_pd[\\'MXSPD\\'])\\nplt.boxplot(df_clean_pd[\"MXSPD\"])\\nplt.show()\\n\\ndf_clean_gust_filter = df_clean.filter(df_clean.GUST < 100).toPandas()\\ngust_median = df_clean_gust_filter[\\'GUST\\'].quantile(0.50)\\ndf_clean_pd[\\'GUST\\'] = np.where(df_clean_pd[\\'GUST\\'] > 100, gust_median, df_clean_pd[\\'GUST\\'])\\nplt.boxplot(df_clean_pd[\"GUST\"])\\nplt.show()\\n\\ndf_clean_max_filter = df_clean.filter(df_clean.MAX < 100).toPandas()\\nmax_median = df_clean_max_filter[\\'MAX\\'].quantile(0.50)\\ndf_clean_pd[\\'MAX\\'] = np.where((df_clean_pd[\\'MAX\\'] < 100) & (df_clean_pd[\\'MAX\\'] > -10), df_clean_pd[\\'MAX\\'], max_median)\\nplt.boxplot(df_clean_pd[\"MAX\"])\\nplt.show()\\n\\ndf_clean_min_filter = df_clean.filter(df_clean.MIN < 100).toPandas()\\nmin_median = df_clean_max_filter[\\'MIN\\'].quantile(0.50)\\ndf_clean_pd[\\'MIN\\'] = np.where((df_clean_pd[\\'MIN\\'] < 100) & (df_clean_pd[\\'MIN\\'] > -10), df_clean_pd[\\'MIN\\'], min_median)\\nplt.boxplot(df_clean_pd[\"MIN\"])\\nplt.show()\\n\\ndf_clean_prcp_filter = df_clean.filter(df_clean.PRCP < 100).toPandas()\\nprcp_median = df_clean_prcp_filter[\\'PRCP\\'].quantile(0.50)\\ndf_clean_pd[\\'PRCP\\'] = np.where(df_clean_pd[\\'PRCP\\'] > 50, prcp_median, df_clean_pd[\\'PRCP\\'])\\nplt.boxplot(df_clean_pd[\"PRCP\"])\\nplt.show()\\n\\ndf_clean_sndp_filter = df_clean.filter(df_clean.SNDP < 100).toPandas()\\nsndp_median = df_clean_sndp_filter[\\'SNDP\\'].quantile(0.50)\\ndf_clean_pd[\\'SNDP\\'] = np.where(df_clean_pd[\\'SNDP\\'] > 200, sndp_median, df_clean_pd[\\'SNDP\\'])\\nplt.boxplot(df_clean_pd[\"SNDP\"])\\nplt.show()\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_clean = df_clean.filter(df_clean.TEMP > -10)\n",
    "#df_clean = df_clean.filter(df_clean.DEWP < 100)\n",
    "#df_clean = df_clean.filter(df_clean.SLP < 4000)\n",
    "#df_clean = df_clean.filter(df_clean.STP < 100)\n",
    "#df_clean = df_clean.filter(df_clean.VISIB < 100)\n",
    "#df_clean = df_clean.filter(df_clean.WDSP < 100)\n",
    "#df_clean = df_clean.filter(df_clean.MXSPD < 100)\n",
    "## df_clean = df_clean.filter(df_clean.GUST < 100)\n",
    "#df_clean = df_clean.filter(df_clean.MAX < 100)\n",
    "#df_clean = df_clean.filter(df_clean.MIN < 100)\n",
    "#df_clean = df_clean.filter(df_clean.PRCP < 100)\n",
    "#df_clean = df_clean.filter(df_clean.SNDP < 100)\n",
    "\n",
    "print(df_clean_n.count())\n",
    "\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.TEMP > -10)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.DEWP < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.SLP < 4000)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.STP < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.VISIB < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.WDSP < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.MXSPD < 100)\n",
    "# df_clean = df_clean.filter(df_clean.GUST < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.MAX < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.MIN < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.PRCP < 100)\n",
    "df_clean_n = df_clean_n.filter(df_clean_n.SNDP < 100)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "temp_median = df_clean_pd['TEMP'].quantile(0.50)\n",
    "df_clean_pd['TEMP'] = np.where(df_clean_pd['TEMP'] < -10, temp_median, df_clean_pd['TEMP'])\n",
    "plt.boxplot(df_clean_pd[\"TEMP\"])\n",
    "plt.show()\n",
    "\n",
    "dewp_median = df_clean_pd['DEWP'].quantile(0.50)\n",
    "df_clean_pd['DEWP'] = np.where(df_clean_pd['DEWP'] > 100, dewp_median, df_clean_pd['DEWP'])\n",
    "plt.boxplot(df_clean_pd[\"DEWP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_slp_filter = df_clean.filter(df_clean.SLP < 4000).toPandas()\n",
    "slp_median = df_clean_slp_filter['SLP'].quantile(0.50)\n",
    "df_clean_pd['SLP'] = np.where(df_clean_pd['SLP'] > 4000, slp_median, df_clean_pd['SLP'])\n",
    "plt.boxplot(df_clean_pd[\"SLP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_stp_filter = df_clean.filter(df_clean.STP < 100).toPandas()\n",
    "stp_median = df_clean_stp_filter['STP'].quantile(0.50)\n",
    "df_clean_pd['STP'] = np.where(df_clean_pd['STP'] > 100, stp_median, df_clean_pd['STP'])\n",
    "plt.boxplot(df_clean_pd[\"STP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_visib_filter = df_clean.filter(df_clean.VISIB < 100).toPandas()\n",
    "visib_median = df_clean_visib_filter['VISIB'].quantile(0.50)\n",
    "df_clean_pd['VISIB'] = np.where(df_clean_pd['VISIB'] > 100, visib_median, df_clean_pd['VISIB'])\n",
    "plt.boxplot(df_clean_pd[\"VISIB\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_wdsp_filter = df_clean.filter(df_clean.WDSP < 100).toPandas()\n",
    "wdsp_median = df_clean_wdsp_filter['WDSP'].quantile(0.50)\n",
    "df_clean_pd['WDSP'] = np.where(df_clean_pd['WDSP'] > 100, wdsp_median, df_clean_pd['WDSP'])\n",
    "plt.boxplot(df_clean_pd[\"WDSP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_mxspd_filter = df_clean.filter(df_clean.MXSPD < 100).toPandas()\n",
    "mxspd_median = df_clean_mxspd_filter['MXSPD'].quantile(0.50)\n",
    "df_clean_pd['MXSPD'] = np.where(df_clean_pd['MXSPD'] > 100, mxspd_median, df_clean_pd['MXSPD'])\n",
    "plt.boxplot(df_clean_pd[\"MXSPD\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_gust_filter = df_clean.filter(df_clean.GUST < 100).toPandas()\n",
    "gust_median = df_clean_gust_filter['GUST'].quantile(0.50)\n",
    "df_clean_pd['GUST'] = np.where(df_clean_pd['GUST'] > 100, gust_median, df_clean_pd['GUST'])\n",
    "plt.boxplot(df_clean_pd[\"GUST\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_max_filter = df_clean.filter(df_clean.MAX < 100).toPandas()\n",
    "max_median = df_clean_max_filter['MAX'].quantile(0.50)\n",
    "df_clean_pd['MAX'] = np.where((df_clean_pd['MAX'] < 100) & (df_clean_pd['MAX'] > -10), df_clean_pd['MAX'], max_median)\n",
    "plt.boxplot(df_clean_pd[\"MAX\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_min_filter = df_clean.filter(df_clean.MIN < 100).toPandas()\n",
    "min_median = df_clean_max_filter['MIN'].quantile(0.50)\n",
    "df_clean_pd['MIN'] = np.where((df_clean_pd['MIN'] < 100) & (df_clean_pd['MIN'] > -10), df_clean_pd['MIN'], min_median)\n",
    "plt.boxplot(df_clean_pd[\"MIN\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_prcp_filter = df_clean.filter(df_clean.PRCP < 100).toPandas()\n",
    "prcp_median = df_clean_prcp_filter['PRCP'].quantile(0.50)\n",
    "df_clean_pd['PRCP'] = np.where(df_clean_pd['PRCP'] > 50, prcp_median, df_clean_pd['PRCP'])\n",
    "plt.boxplot(df_clean_pd[\"PRCP\"])\n",
    "plt.show()\n",
    "\n",
    "df_clean_sndp_filter = df_clean.filter(df_clean.SNDP < 100).toPandas()\n",
    "sndp_median = df_clean_sndp_filter['SNDP'].quantile(0.50)\n",
    "df_clean_pd['SNDP'] = np.where(df_clean_pd['SNDP'] > 200, sndp_median, df_clean_pd['SNDP'])\n",
    "plt.boxplot(df_clean_pd[\"SNDP\"])\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb85ab95-726f-44bb-83f5-b03de4b673dc",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d25d075-c1e4-4514-9c8b-6097cdc0d8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:28:13 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:28:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:28:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:28:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:28:43 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:28:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:28:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:28:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 325:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           NextDay|\n",
      "+-------+------------------+\n",
      "|  count|             75838|\n",
      "|   mean|0.5005142540678815|\n",
      "| stddev|0.5000030320739765|\n",
      "|    min|                 0|\n",
      "|    25%|                 0|\n",
      "|    50%|                 1|\n",
      "|    75%|                 1|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df = spark.createDataFrame([['a',1],['b',1],['c',1],['d',1], ['e',1], ['f',1], ['x', 0], ['y', 0]], ['feature', 'label'])\n",
    "# df.show()\n",
    "\n",
    "#major_df = df_clean.filter(col(\"ItRained\") == 0)\n",
    "#minor_df = df_clean.filter(col(\"ItRained\") == 1)\n",
    "#ratio = major_df.count()/minor_df.count()\n",
    "#sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "#df_clean = sampled_majority_df.unionAll(minor_df)\n",
    "#df_clean.select(\"ItRained\").summary().show()\n",
    "print(df_clean_n.count())\n",
    "\n",
    "major_df_n = df_clean_n.filter(col(\"NextDay\") == 0)\n",
    "minor_df_n = df_clean_n.filter(col(\"NextDay\") == 1)\n",
    "ratio_n = major_df_n.count()/minor_df_n.count()\n",
    "sampled_majority_df_n = major_df_n.sample(False, 1/ratio_n)\n",
    "df_clean_n = sampled_majority_df_n.unionAll(minor_df_n)\n",
    "df_clean_n.select(\"NextDay\").summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5cef332-5849-4d80-ba33-c4edaa8aa1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:29:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:29:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:29:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:29:59 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 348:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60783 rows in the training set and 15055 in the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# df_clean = myspark.createDataFrame(df_clean_pd)\n",
    "#df_train, df_test = df_clean.randomSplit([0.8,0.2], seed = 42)\n",
    "#df_train.cache()\n",
    "#print(f\"There are {df_train.count()} rows in the training set and {df_test.count()} in the test set\")\n",
    "\n",
    "df_train_n, df_test_n = df_clean_n.randomSplit([0.8,0.2], seed = 42)\n",
    "df_train_n.cache()\n",
    "print(f\"There are {df_train_n.count()} rows in the training set and {df_test_n.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6883501f-c09a-4204-822f-ade89542085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/23 15:30:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:30:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:26 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/23 15:31:55 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 420:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  41.806708734639656 2 % \n",
      "True Negative:  31.8365991364995 % \n",
      "False Positive:  18.432414480239125 % \n",
      "False Negative:  7.924277648621721 % \n",
      "Prediction count: 15055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprediction_label = df_prediction.select(\"prediction\", \"ItRained\")\\n\\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\\'prediction\\')\\n\\nprint(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\\n\\nlr = LinearRegression(featuresCol=\"features\", labelCol=\"ItRained\")\\nlr_model = lr.fit(vec_df_train)\\navg_ItRained = float(df_train.select(avg(\"ItRained\")).first()[0])\\ndf_pred = df_train.withColumn(\"avg_ItRained_prediction\", lit(avg_ItRained))\\navg_ItRained\\nevaluator = RegressionEvaluator(predictionCol=\"avg_ItRained_prediction\", labelCol=\"ItRained\", metricName=\"rmse\")\\nprint(f\"The RMSE for predicting the average frshtt is: {evaluator.evaluate(df_pred):.2f}\")\\npipeline = Pipeline(stages=[vec_assembler, lr_model])\\n\\n# get the model (as transformer)\\npipeline_model = pipeline.fit(df_train)\\ndf_prediction = pipeline_model.transform(df_test)\\n\\n# show the columns worth to be looked at\\ndf_prediction.select(\"features\",\"ItRained\",\"prediction\").sample(False, 0.1).sort(\"ItRained\", ascending=False).show(200)\\n\\ndf_prediction.columns\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vec_assembler = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "#vec_df_train = vec_assembler.transform(df_train)\n",
    "#\n",
    "## show the content of the columns bedrooms, features and price\n",
    "## vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "#\n",
    "#lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"ItRained\")\n",
    "#pipeline = Pipeline(stages=[vec_assembler, lsvc])\n",
    "#pipeline_model = pipeline.fit(df_train)\n",
    "#df_prediction = pipeline_model.transform(df_test)\n",
    "## df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "#\n",
    "#prediction_label = df_prediction.select(\"prediction\", \"ItRained\")  \n",
    "#\n",
    "## supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "## it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "#\n",
    "#evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='ItRained', )\n",
    "#\n",
    "## print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "#\n",
    "#n = df_prediction.count()\n",
    "#tp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"ItRained == prediction\")).count()\n",
    "#tn = df_prediction.filter(expr(\"prediction <= 0\") & expr(\"ItRained == prediction\")).count()\n",
    "#fp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"ItRained != prediction\")).count()\n",
    "#fn = n - tp - tn - fp\n",
    "#print(\"True Positive: \",tp/n * 100, 2,\"%\", \"\\nTrue Negative: \", tn/n * 100,\"%\",\n",
    "#      \"\\nFalse Positive: \", fp/n * 100 ,\"%\", \"\\nFalse Negative: \", fn/n * 100,\"%\", \n",
    "#      \"\\nPrediction count:\", n)\n",
    "\n",
    "\n",
    "#====================================================================================================================================================\n",
    "\n",
    "vec_assembler_n = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'STP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "vec_df_train_n = vec_assembler_n.transform(df_train_n)\n",
    "\n",
    "# show the content of the columns bedrooms, features and price\n",
    "# vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "\n",
    "lsvc_n = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"NextDay\")\n",
    "pipeline_n = Pipeline(stages=[vec_assembler_n, lsvc_n])\n",
    "pipeline_model_n = pipeline_n.fit(df_train_n)\n",
    "df_prediction_n = pipeline_model_n.transform(df_test_n)\n",
    "# df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "\n",
    "prediction_label_n = df_prediction_n.select(\"prediction\", \"NextDay\")  \n",
    "\n",
    "# supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "# it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "evaluator_n = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='NextDay', )\n",
    "\n",
    "# print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "n_n = df_prediction_n.count()\n",
    "tp_n = df_prediction_n.filter(expr(\"prediction > 0\") & expr(\"NextDay == prediction\")).count()\n",
    "tn_n = df_prediction_n.filter(expr(\"prediction <= 0\") & expr(\"NextDay == prediction\")).count()\n",
    "fp_n = df_prediction_n.filter(expr(\"prediction > 0\") & expr(\"NextDay != prediction\")).count()\n",
    "fn_n = n_n - tp_n - tn_n - fp_n\n",
    "print(\"True Positive: \",tp_n/n_n * 100, 2,\"%\", \"\\nTrue Negative: \", tn_n/n_n * 100,\"%\",\n",
    "      \"\\nFalse Positive: \", fp_n/n_n * 100 ,\"%\", \"\\nFalse Negative: \", fn_n/n_n * 100,\"%\", \n",
    "      \"\\nPrediction count:\", n_n)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "prediction_label = df_prediction.select(\"prediction\", \"ItRained\")\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
    "\n",
    "print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"ItRained\")\n",
    "lr_model = lr.fit(vec_df_train)\n",
    "avg_ItRained = float(df_train.select(avg(\"ItRained\")).first()[0])\n",
    "df_pred = df_train.withColumn(\"avg_ItRained_prediction\", lit(avg_ItRained))\n",
    "avg_ItRained\n",
    "evaluator = RegressionEvaluator(predictionCol=\"avg_ItRained_prediction\", labelCol=\"ItRained\", metricName=\"rmse\")\n",
    "print(f\"The RMSE for predicting the average frshtt is: {evaluator.evaluate(df_pred):.2f}\")\n",
    "pipeline = Pipeline(stages=[vec_assembler, lr_model])\n",
    "\n",
    "# get the model (as transformer)\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "df_prediction = pipeline_model.transform(df_test)\n",
    "\n",
    "# show the columns worth to be looked at\n",
    "df_prediction.select(\"features\",\"ItRained\",\"prediction\").sample(False, 0.1).sort(\"ItRained\", ascending=False).show(200)\n",
    "\n",
    "df_prediction.columns\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
