{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0eb566d-3e66-4969-9c62-d8224b97b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import nbimporter\n",
    "import Useful_Visualization_Functions\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "#from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, explode, array, lit, expr\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f451b-eead-428f-8905-50e9bf04c743",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec289c7-462c-4b05-ad4c-fc8213e88018",
   "metadata": {},
   "outputs": [],
   "source": [
    "myspark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AWS-Spark\")\\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0fc04-e91f-4478-901f-e6fbac54d638",
   "metadata": {},
   "source": [
    "### Import parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a5c5e9-f17c-424e-a705-74b21a1fc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = myspark.read.parquet(\"clean-noaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d117092-0d7f-416d-9076-400fd77528bc",
   "metadata": {},
   "source": [
    "### Choice of target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86923ab2-5e48-440c-98d4-b9fa170de4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"ItRained\"\n",
    "#target_column = \"ItRainedOrSnowed\"\n",
    "#target_column = \"NextDayIR\"\n",
    "#target_column = \"NextDayIROS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e9254-dd5c-4336-8295-e3c48f11af27",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a3c386-4f9b-4266-a1ce-eebc75599307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|          ItRained|\n",
      "+-------+------------------+\n",
      "|  count|            302327|\n",
      "|   mean| 0.499429425754233|\n",
      "| stddev|0.5000005013656338|\n",
      "|    min|                 0|\n",
      "|    25%|                 0|\n",
      "|    50%|                 0|\n",
      "|    75%|                 1|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_df = df_clean.filter(col(target_column) == 0)\n",
    "one_df = df_clean.filter(col(target_column) == 1)\n",
    "\n",
    "major_df, minor_df = (zero_df, one_df) if zero_df.count() > one_df.count() else (one_df, zero_df)\n",
    "    \n",
    "ratio = major_df.count()/minor_df.count()\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "df_next = sampled_majority_df.unionAll(minor_df)\n",
    "df_next.select(target_column).summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42836d4e-72c7-4aa2-ab6c-8ccf0ddd6a0c",
   "metadata": {},
   "source": [
    "### Split into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e19a04-a674-46a4-8848-5cf7483c3ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 242044 rows in the training set and 60283 in the test set\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df_next.randomSplit([0.8,0.2], seed = 42)\n",
    "df_train.cache()\n",
    "print(f\"There are {df_train.count()} rows in the training set and {df_test.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931adea-344e-4efa-9995-7a18d624388c",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f94648dc-a551-4be0-a24c-1ed429a762ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['TEMP', 'DEWP', 'SLP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "vec_df_train = vec_assembler.transform(df_train)\n",
    "\n",
    "# show the content of the columns bedrooms, features and price\n",
    "# vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=target_column)\n",
    "pipeline = Pipeline(stages=[vec_assembler, lsvc])\n",
    "pipeline_model_next = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee60359-0c7b-4e12-afbb-7211d0d8b6f0",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "696b84c6-6e3f-4618-8a33-ea43bb686b6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: 45.01269014481694 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m fp \u001b[38;5;241m=\u001b[39m df_prediction\u001b[38;5;241m.\u001b[39mfilter(expr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction > 0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m expr(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_column\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m     17\u001b[0m fn \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m-\u001b[39m tp \u001b[38;5;241m-\u001b[39m tn \u001b[38;5;241m-\u001b[39m fp\n\u001b[0;32m---> 18\u001b[0m true_positive_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtp\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m true_negative_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(tn\u001b[38;5;241m/\u001b[39mn \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     20\u001b[0m false_postive_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(fp\u001b[38;5;241m/\u001b[39mn \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/functions.py:1300\u001b[0m, in \u001b[0;36mround\u001b[0;34m(col, scale)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;124;03mRound the given value to `scale` decimal places using HALF_UP rounding mode if `scale` >= 0\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;124;03mor at integral part when `scale` < 0.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03m[Row(r=3.0)]\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[0;32m-> 1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mfunctions\u001b[38;5;241m.\u001b[39mround(\u001b[43m_to_java_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m, scale))\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/column.py:45\u001b[0m, in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     43\u001b[0m     jcol \u001b[38;5;241m=\u001b[39m _create_column_from_name(col)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument, not a string or column: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor column literals, use \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstruct\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_map\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(col, \u001b[38;5;28mtype\u001b[39m(col)))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jcol\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: 45.01269014481694 of type <class 'float'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "df_prediction = pipeline_model_next.transform(df_test)\n",
    "# df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "\n",
    "prediction_label = df_prediction.select(\"prediction\", target_column)  \n",
    "\n",
    "# supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "# it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol=target_column, )\n",
    "\n",
    "# print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "n = df_prediction.count()\n",
    "tp = df_prediction.filter(expr(\"prediction > 0\") & expr(f\"{target_column} == prediction\")).count()\n",
    "tn = df_prediction.filter(expr(\"prediction <= 0\") & expr(f\"{target_column} == prediction\")).count()\n",
    "fp = df_prediction.filter(expr(\"prediction > 0\") & expr(f\"{target_column} != prediction\")).count()\n",
    "fn = n - tp - tn - fp\n",
    "true_positive_percentage = round(tp/n * 100, 2)\n",
    "true_negative_percentage = round(tn/n * 100, 2)\n",
    "false_postive_percentage = round(fp/n * 100, 2)\n",
    "false_negative_percentage = round(fn/n * 100, 2)\n",
    "accuracy = round((tp/n + tn/n) * 100, 2) \n",
    "print(\"True Positive: \",true_positive_percentage,\"%\", \"\\nTrue Negative: \", true_negative_percentage,\"%\",\n",
    "      \"\\nFalse Positive: \", false_postive_percentage ,\"%\", \"\\nFalse Negative: \", false_negative_percentage,\"%\" \n",
    "      \"\\nPrediction count:\", n)\n",
    "print(\"Accuracy: \", accuracy, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
