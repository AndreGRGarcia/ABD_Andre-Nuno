{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0eb566d-3e66-4969-9c62-d8224b97b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import nbimporter\n",
    "import Useful_Visualization_Functions\n",
    "from pyspark.ml import *\n",
    "from pyspark.sql import *\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, explode, array, lit\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f451b-eead-428f-8905-50e9bf04c743",
   "metadata": {},
   "source": [
    "### Build spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec289c7-462c-4b05-ad4c-fc8213e88018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/24 13:13:25 WARN Utils: Your hostname, saltedcookie-PC resolves to a loopback address: 127.0.1.1; using 192.168.1.199 instead (on interface enp42s0)\n",
      "22/05/24 13:13:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/24 13:13:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/05/24 13:13:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/24 13:13:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "22/05/24 13:13:26 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "myspark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"AWS-Spark\")\\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa0fc04-e91f-4478-901f-e6fbac54d638",
   "metadata": {},
   "source": [
    "### Import parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a5c5e9-f17c-424e-a705-74b21a1fc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = myspark.read.parquet(\"clean-noaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ac7e8-1fec-4085-b75d-a7c35b18caae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Current day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96393448-46cc-4d42-a295-49fd7b9fe13a",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "155fa56d-c617-4c25-a735-870e6b8341cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|          ItRained|\n",
      "+-------+------------------+\n",
      "|  count|            301999|\n",
      "|   mean|0.4999718542114378|\n",
      "| stddev|0.5000008270271799|\n",
      "|    min|                 0|\n",
      "|    25%|                 0|\n",
      "|    50%|                 0|\n",
      "|    75%|                 1|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_df_cur = df_clean.filter(col(\"ItRained\") == 0)\n",
    "one_df_cur = df_clean.filter(col(\"ItRained\") == 1)\n",
    "\n",
    "major_df_cur, minor_df_cur = (zero_df_cur, one_df_cur) if zero_df_cur.count() > one_df_cur.count() else (one_df_cur, zero_df_cur)\n",
    "\n",
    "#if zero_df.count() > one_df.count():\n",
    "#    major_df = zero_df\n",
    "#    minor_df = one_df\n",
    "#else:\n",
    "#    major_df = one_df\n",
    "#    minor_df = zero_df\n",
    "    \n",
    "ratio_cur = major_df_cur.count()/minor_df_cur.count()\n",
    "sampled_majority_df_cur = major_df_cur.sample(False, 1/ratio_cur)\n",
    "df_cur = sampled_majority_df_cur.unionAll(minor_df_cur)\n",
    "df_cur.select(\"ItRained\").summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e34ca2-1dd9-4e04-b665-e6dfd2467d7f",
   "metadata": {},
   "source": [
    "### Split into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e2d3eac-51d9-40ba-865c-fc3920a95420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 241772 rows in the training set and 60227 in the test set\n"
     ]
    }
   ],
   "source": [
    "df_train_cur, df_test_cur = df_cur.randomSplit([0.8,0.2], seed = 42)\n",
    "df_train_cur.cache()\n",
    "print(f\"There are {df_train_cur.count()} rows in the training set and {df_test_cur.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3d933-d352-4a1f-be2a-aa0ddd1761bc",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c7711ff-1a09-4fad-ad24-e4f3950a3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler_cur = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "vec_df_train_cur = vec_assembler_cur.transform(df_train_cur)\n",
    "\n",
    "# show the content of the columns bedrooms, features and price\n",
    "# vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "\n",
    "lsvc_cur = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"ItRained\")\n",
    "pipeline_cur = Pipeline(stages=[vec_assembler_cur, lsvc_cur])\n",
    "pipeline_model_cur = pipeline_cur.fit(df_train_cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119229db-dc2e-4dc0-863e-ca9cd11aeab2",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a1e7a96-9923-4a9e-94d4-e6512e68dfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  45.08110980125193 2 % \n",
      "True Negative:  36.04031414481877 % \n",
      "False Positive:  13.930629119829977 % \n",
      "False Negative:  4.947946934099325 % \n",
      "Prediction count: 60227\n",
      "Accuracy:  81.1214239460707\n"
     ]
    }
   ],
   "source": [
    "df_prediction_cur = pipeline_model_cur.transform(df_test_cur)\n",
    "# df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "\n",
    "prediction_label_cur = df_prediction_cur.select(\"prediction\", \"ItRained\")  \n",
    "\n",
    "# supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "# it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "evaluator_cur = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='ItRained', )\n",
    "\n",
    "# print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "n_cur = df_prediction_cur.count()\n",
    "tp_cur = df_prediction_cur.filter(expr(\"prediction > 0\") & expr(\"ItRained == prediction\")).count()\n",
    "tn_cur = df_prediction_cur.filter(expr(\"prediction <= 0\") & expr(\"ItRained == prediction\")).count()\n",
    "fp_cur = df_prediction_cur.filter(expr(\"prediction > 0\") & expr(\"ItRained != prediction\")).count()\n",
    "fn_cur = n_cur - tp_cur - tn_cur - fp_cur\n",
    "print(\"True Positive: \",tp_cur/n_cur * 100, 2,\"%\", \"\\nTrue Negative: \", tn_cur/n_cur * 100,\"%\",\n",
    "      \"\\nFalse Positive: \", fp_cur/n_cur * 100 ,\"%\", \"\\nFalse Negative: \", fn_cur/n_cur* 100,\"%\", \n",
    "      \"\\nPrediction count:\", n_cur)\n",
    "print(\"Accuracy: \", (tp_cur/n_cur * 100) + (tn_cur/n_cur * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50144140-0f20-49a7-8645-96b2382d947b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Next Day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55e9254-dd5c-4336-8295-e3c48f11af27",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96a3c386-4f9b-4266-a1ce-eebc75599307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           NextDay|\n",
      "+-------+------------------+\n",
      "|  count|            293588|\n",
      "|   mean|0.4997036663623854|\n",
      "| stddev|0.5000007637218347|\n",
      "|    min|                 0|\n",
      "|    25%|                 0|\n",
      "|    50%|                 0|\n",
      "|    75%|                 1|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero_df = df_clean.filter(col(\"NextDay\") == 0)\n",
    "one_df = df_clean.filter(col(\"NextDay\") == 1)\n",
    "\n",
    "major_df, minor_df = (zero_df, one_df) if zero_df.count() > one_df.count() else (one_df, zero_df)\n",
    "\n",
    "#if zero_df.count() > one_df.count():\n",
    "#    major_df = zero_df\n",
    "#    minor_df = one_df\n",
    "#else:\n",
    "#    major_df = one_df\n",
    "#    minor_df = zero_df\n",
    "    \n",
    "ratio = major_df.count()/minor_df.count()\n",
    "sampled_majority_df = major_df.sample(False, 1/ratio)\n",
    "df_next = sampled_majority_df.unionAll(minor_df)\n",
    "df_next.select(\"NextDay\").summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42836d4e-72c7-4aa2-ab6c-8ccf0ddd6a0c",
   "metadata": {},
   "source": [
    "### Split into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7e19a04-a674-46a4-8848-5cf7483c3ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 234992 rows in the training set and 58596 in the test set\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = df_next.randomSplit([0.8,0.2], seed = 42)\n",
    "df_train.cache()\n",
    "print(f\"There are {df_train.count()} rows in the training set and {df_test.count()} in the test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931adea-344e-4efa-9995-7a18d624388c",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f94648dc-a551-4be0-a24c-1ed429a762ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_assembler = VectorAssembler(inputCols=['TEMP', 'DEWP','SLP', 'VISIB', 'WDSP', 'MXSPD', 'MAX', 'MIN'], outputCol=\"features\")\n",
    "vec_df_train = vec_assembler.transform(df_train)\n",
    "\n",
    "# show the content of the columns bedrooms, features and price\n",
    "# vec_df_train.select(\"TEMP\",\"DEWP\",\"features\").show(200)\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"NextDay\")\n",
    "pipeline = Pipeline(stages=[vec_assembler, lsvc])\n",
    "pipeline_model_next = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee60359-0c7b-4e12-afbb-7211d0d8b6f0",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "696b84c6-6e3f-4618-8a33-ea43bb686b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive:  42.460236193596835 % \n",
      "True Negative:  31.00894258993788 % \n",
      "False Positive:  18.934739572667077 % \n",
      "False Negative:  7.596081643798211 % \n",
      "Prediction count: 58596\n",
      "Accuracy:  73.46917878353472\n"
     ]
    }
   ],
   "source": [
    "df_prediction = pipeline_model_next.transform(df_test)\n",
    "# df_prediction.select(\"features\", \"ItRained\", \"prediction\").sort(\"prediction\", ascending=False).show(200)\n",
    "\n",
    "prediction_label = df_prediction.select(\"prediction\", \"NextDay\")  \n",
    "\n",
    "# supports metricName=\"areaUnderROC\" (default) and \"areaUnderPR\"\n",
    "# it relates sensitivity (TP rate) and specificity (FP rate)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='NextDay', )\n",
    "\n",
    "# print(\"areaUnderROC = \" + str(evaluator.evaluate(prediction_label)))\n",
    "\n",
    "n = df_prediction.count()\n",
    "tp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"NextDay == prediction\")).count()\n",
    "tn = df_prediction.filter(expr(\"prediction <= 0\") & expr(\"NextDay == prediction\")).count()\n",
    "fp = df_prediction.filter(expr(\"prediction > 0\") & expr(\"NextDay != prediction\")).count()\n",
    "fn = n - tp - tn - fp\n",
    "print(\"True Positive: \",tp/n * 100,\"%\", \"\\nTrue Negative: \", tn/n * 100,\"%\",\n",
    "      \"\\nFalse Positive: \", fp/n * 100 ,\"%\", \"\\nFalse Negative: \", fn/n * 100,\"%\", \n",
    "      \"\\nPrediction count:\", n)\n",
    "print(\"Accuracy: \", (tp/n * 100) + (tn/n * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
